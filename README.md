# seeing-eye-dog
except it talks to you in english and it's just your phone

### learning to use mlx by 
1. doing vlm inference with quantized models.
2. deploy on device for (hopefully) realtime inference
3. make it better idk

### todos
[x] baby's first local inference
[ ] connect to laptop webcam to get images (start off sampling every 5 secs or so)
[ ] text to speech (in future use fusion model to directly go from image/prompt to speech)
[ ] make it faster